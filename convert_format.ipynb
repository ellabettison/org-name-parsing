{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/config.json from cache at /Users/ellabettison/.cache/huggingface/transformers/8fb343045f345372593fb03cc8edd339757b9b5fa164bfd4a071c33d81906423.81e683d6e4f3240a109c9cfd0742b01d443acc6fc2b120b20796fb85ddf0f393\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ellabettison/.cache/huggingface/transformers/a745361317c5abff68001c41dcd59cb03a59590cd41b528cee213f748d6a5383.1369ebdf147c85eaf03a9d4c661bb19c36a776431d4ef10065ac548d08d4368c\n",
      "loading file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/special_tokens_map.json from cache at /Users/ellabettison/.cache/huggingface/transformers/1ec992491addc8a43e9196bea3ccaf98f3958ce101f111ba9096813cf1ab493c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ellabettison/.cache/huggingface/transformers/f795d176d70a24ac32d30bc7b2ee9a6743e562fb84ea9fa94aae5082ebb18cf6.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
      "loading configuration file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/config.json from cache at /Users/ellabettison/.cache/huggingface/transformers/8fb343045f345372593fb03cc8edd339757b9b5fa164bfd4a071c33d81906423.81e683d6e4f3240a109c9cfd0742b01d443acc6fc2b120b20796fb85ddf0f393\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/config.json from cache at /Users/ellabettison/.cache/huggingface/transformers/8fb343045f345372593fb03cc8edd339757b9b5fa164bfd4a071c33d81906423.81e683d6e4f3240a109c9cfd0742b01d443acc6fc2b120b20796fb85ddf0f393\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlpaueb/legal-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 2), (3, 4), (5, 7), (7, 8), (0, 0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "tokens = tokenizer(\"On y va.\", return_offsets_mapping=True)\n",
    "tokens.offset_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'ID',\n",
       " 2: 'PER',\n",
       " 3: 'IND',\n",
       " 4: 'STP',\n",
       " 5: 'LOC',\n",
       " 6: 'ORG',\n",
       " 7: 'NAT',\n",
       " 8: 'COL',\n",
       " 9: 'LEG',\n",
       " 10: 'ACR',\n",
       " 11: 'STR',\n",
       " 12: 'SCP',\n",
       " 13: 'MOD'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [\n",
    "  \"ID\",\n",
    "  \"PER\",\n",
    "  \"IND\",\n",
    "  \"STP\",\n",
    "  \"LOC\",\n",
    "  \"ORG\",\n",
    "  \"NAT\",\n",
    "  \"COL\",\n",
    "  \"LEG\",\n",
    "  \"ACR\",\n",
    "  \"STR\",\n",
    "  \"SCP\",\n",
    "  \"MOD\"\n",
    "]\n",
    "id2tag = {i+1:v for i, v in enumerate(tags)}\n",
    "tag2id = {v:i+1 for i, v in enumerate(tags)}\n",
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-ID',\n",
       " 3: 'B-PER',\n",
       " 5: 'B-IND',\n",
       " 7: 'B-STP',\n",
       " 9: 'B-LOC',\n",
       " 11: 'B-ORG',\n",
       " 13: 'B-NAT',\n",
       " 15: 'B-COL',\n",
       " 17: 'B-LEG',\n",
       " 19: 'B-ACR',\n",
       " 21: 'B-STR',\n",
       " 23: 'B-SCP',\n",
       " 25: 'B-MOD',\n",
       " 2: 'I-ID',\n",
       " 4: 'I-PER',\n",
       " 6: 'I-IND',\n",
       " 8: 'I-STP',\n",
       " 10: 'I-LOC',\n",
       " 12: 'I-ORG',\n",
       " 14: 'I-NAT',\n",
       " 16: 'I-COL',\n",
       " 18: 'I-LEG',\n",
       " 20: 'I-ACR',\n",
       " 22: 'I-STR',\n",
       " 24: 'I-SCP',\n",
       " 26: 'I-MOD'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {\n",
    "    'O': 0, \n",
    "    **{f'B-{k}': 2*v - 1 for k, v in tag2id.items()},\n",
    "    **{f'I-{k}': 2*v for k, v in tag2id.items()}\n",
    "}\n",
    "\n",
    "id2label = {v:k for k, v in label2id.items()}\n",
    "\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_role_in_span(token_start: int, token_end: int, span_start: int, span_end: int):\n",
    "    \"\"\"\n",
    "    Check if the token is inside a span.\n",
    "    Args:\n",
    "      - token_start, token_end: Start and end offset of the token\n",
    "      - span_start, span_end: Start and end of the span\n",
    "    Returns:\n",
    "      - \"B\" if beginning\n",
    "      - \"I\" if inner\n",
    "      - \"O\" if outer\n",
    "      - \"N\" if not valid token (like <SEP>, <CLS>, <UNK>)\n",
    "    \"\"\"\n",
    "    if token_end <= token_start:\n",
    "        return \"N\"\n",
    "    if token_start < span_start or token_end > span_end:\n",
    "        return \"O\"\n",
    "    if token_start > span_start:\n",
    "        return \"I\"\n",
    "    else:\n",
    "        return \"B\"\n",
    "\n",
    "MAX_LENGTH = 16\n",
    "\n",
    "def tokenize_and_adjust_labels(sample):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - sample (dict): {\"id\": \"...\", \"text\": \"...\", \"tags\": [{\"start\": ..., \"end\": ..., \"tag\": ...}, ...]\n",
    "    Returns:\n",
    "        - The tokenized version of `sample` and the labels of each token.\n",
    "    \"\"\"\n",
    "    # Tokenize the text, keep the start and end positions of tokens with `return_offsets_mapping` option\n",
    "    # Use max_length and truncation to ajust the text length\n",
    "    tokenized = tokenizer(sample[\"text\"], \n",
    "                          return_offsets_mapping=True, \n",
    "                          padding=\"max_length\", \n",
    "                          max_length=MAX_LENGTH,\n",
    "                          truncation=True)\n",
    "    \n",
    "    # We are doing a multilabel classification task at each token, we create a list of size len(label2id)=13 \n",
    "    # for the 13 labels\n",
    "    labels = [[0 for _ in label2id.keys()] for _ in range(MAX_LENGTH)]\n",
    "    \n",
    "    # Scan all the tokens and spans, assign 1 to the corresponding label if the token lies at the beginning\n",
    "    # or inside the spans\n",
    "    for (token_start, token_end), token_labels in zip(tokenized[\"offset_mapping\"], labels):\n",
    "        for span in sample[\"tags\"]:\n",
    "            role = get_token_role_in_span(token_start, token_end, span[\"start\"], span[\"end\"])\n",
    "            if role == \"B\":\n",
    "                token_labels[label2id[f\"B-{span['tag']}\"]] = 1\n",
    "            elif role == \"I\":\n",
    "                token_labels[label2id[f\"I-{span['tag']}\"]] = 1\n",
    "    \n",
    "    return {**tokenized, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (2.5.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (2022.8.2)\n",
      "Requirement already satisfied: xxhash in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (0.10.0)\n",
      "Requirement already satisfied: pandas in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (1.23.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: multiprocess in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: aiohttp in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: packaging in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pandas->datasets) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: spacy in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (1.23.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: jinja2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: setuptools in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (8.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.2)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def spacy_to_jsonl(spacy_eg, filename):\n",
    "    json_ls = []\n",
    "\n",
    "    for i, sent in enumerate(spacy_eg):\n",
    "        json_l = {}\n",
    "        tags = []\n",
    "        for token in sent.spans['sc']:\n",
    "            tags.append({'end':token.end_char, 'start':token.start_char, 'tag':token.label_})\n",
    "        json_l['tags'] = tags\n",
    "        json_l['id'] = i\n",
    "        json_l['text'] = sent.text\n",
    "\n",
    "        json_ls.append(json_l)\n",
    "    with open(filename, 'w') as fp:\n",
    "        fp.write(\n",
    "            '[' +\n",
    "            ',\\n'.join(json.dumps(i) for i in json_ls) +\n",
    "        ']\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/added_tokens.json. We won't load it.\n",
      "loading file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/vocab.json\n",
      "loading file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/merges.txt\n",
      "loading file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/tokenizer.json\n",
      "loading file None\n",
      "loading file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/special_tokens_map.json\n",
      "loading file /var/folders/yg/f3nqzkxd36d391q7jr9jxtv00000gn/T/tmpea1ai0ca/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.load('output/model-best')\n",
    "\n",
    "def load_spacy(input_path:str) -> list:\n",
    "    doc_bin = DocBin().from_disk(input_path)\n",
    "    return (list(doc_bin.get_docs(nlp.vocab)))\n",
    "\n",
    "test_examples = load_spacy(\"../spacy_data/dev.spacy\")\n",
    "spacy_to_jsonl(test_examples, \"test_data.jsonl\")\n",
    "\n",
    "test_examples = load_spacy(\"../spacy_data/train.spacy\")\n",
    "spacy_to_jsonl(test_examples, \"train_data.jsonl\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c89e8d4d06f7b4f5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/ellabettison/.cache/huggingface/datasets/json/default-c89e8d4d06f7b4f5/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1370.24it/s]\n",
      "\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 132.94it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[AUsing custom data configuration default-0f492f6c38e0465b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/ellabettison/.cache/huggingface/datasets/json/default-c89e8d4d06f7b4f5/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset json/default to /Users/ellabettison/.cache/huggingface/datasets/json/default-0f492f6c38e0465b/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2132.34it/s]\n",
      "\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 236.23it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/ellabettison/.cache/huggingface/datasets/json/default-0f492f6c38e0465b/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tags': [{'end': 2, 'start': 0, 'tag': 'ID'},\n",
       "  {'end': 2, 'start': 0, 'tag': 'ACR'}],\n",
       " 'id': 0,\n",
       " 'text': 'CA'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "train_ds = Dataset.from_json(\"test_data.jsonl\")\n",
    "val_ds = Dataset.from_json(\"train_data.jsonl\")\n",
    "\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CA\n",
      "ID         - CA\n",
      "ACR        - CA\n",
      "\n",
      "CDCA\n",
      "ACR        - CDCA\n",
      "ID         - CDCA\n",
      "\n",
      "bottom line training and consulting\n",
      "ID         - bottom line\n",
      "IND        - training\n",
      "STP        - and\n",
      "IND        - consulting\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    example = train_ds[i]\n",
    "    print(f\"\\n{example['text']}\")\n",
    "    for tag_item in example[\"tags\"]:\n",
    "        print(tag_item[\"tag\"].ljust(10), \"-\", example[\"text\"][tag_item[\"start\"]: tag_item[\"end\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "100%|██████████| 234/234 [00:00<00:00, 1961.40ex/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 938/938 [00:00<00:00, 2836.04ex/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_ds = train_ds.map(tokenize_and_adjust_labels, remove_columns=train_ds.column_names)\n",
    "tokenized_val_ds = val_ds.map(tokenize_and_adjust_labels, remove_columns=val_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = tokenized_train_ds[0]\n",
    "sample[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2121, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [[0, 0], [0, 2], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]], 'labels': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sklearn in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "n_labels = len(id2label)\n",
    "\n",
    "def divide(a: int, b: int):\n",
    "    return a / b if b > 0 else 0\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Customize the `compute_metrics` of `transformers`\n",
    "    Args:\n",
    "        - p (tuple):      2 numpy arrays: predictions and true_labels\n",
    "    Returns:\n",
    "        - metrics (dict): f1 score on \n",
    "    \"\"\"\n",
    "    # (1)\n",
    "    predictions, true_labels = p\n",
    "    \n",
    "    # (2)\n",
    "    predicted_labels = np.where(predictions > 0, np.ones(predictions.shape), np.zeros(predictions.shape))\n",
    "    metrics = {}\n",
    "    \n",
    "    # (3)\n",
    "    cm = multilabel_confusion_matrix(true_labels.reshape(-1, n_labels), predicted_labels.reshape(-1, n_labels))\n",
    "    \n",
    "    # (4) \n",
    "    for label_idx, matrix in enumerate(cm):\n",
    "        if label_idx == 0:\n",
    "            continue # We don't care about the label \"O\"\n",
    "        tp, fp, fn = matrix[1, 1], matrix[0, 1], matrix[1, 0]\n",
    "        precision = divide(tp, tp + fp)\n",
    "        recall = divide(tp, tp + fn)\n",
    "        f1 = divide(2 * precision * recall, precision + recall)\n",
    "        metrics[f\"f1_{id2label[label_idx]}\"] = f1\n",
    "        \n",
    "    # (5)\n",
    "    macro_f1 = sum(list(metrics.values())) / (n_labels - 1)\n",
    "    metrics[\"macro_f1\"] = macro_f1\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import RobertaPreTrainedModel, RobertaModel\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    ROBERTA_INPUTS_DOCSTRING,\n",
    "    ROBERTA_START_DOCSTRING,\n",
    "    RobertaEmbeddings,\n",
    "    _TOKENIZER_FOR_DOC\n",
    ")\n",
    "from typing import Optional, Union, Tuple\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RobertaForSpanCategorization(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "    \n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels.float())\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/fine_tune_bert_output_span_cat\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    learning_rate=2.5e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 10,\n",
    "    save_strategy='steps',\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='macro_f1',\n",
    "    seed=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/config.json from cache at /Users/ellabettison/.cache/huggingface/transformers/8fb343045f345372593fb03cc8edd339757b9b5fa164bfd4a071c33d81906423.81e683d6e4f3240a109c9cfd0742b01d443acc6fc2b120b20796fb85ddf0f393\n",
      "You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-ID\",\n",
      "    \"2\": \"I-ID\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-IND\",\n",
      "    \"6\": \"I-IND\",\n",
      "    \"7\": \"B-STP\",\n",
      "    \"8\": \"I-STP\",\n",
      "    \"9\": \"B-LOC\",\n",
      "    \"10\": \"I-LOC\",\n",
      "    \"11\": \"B-ORG\",\n",
      "    \"12\": \"I-ORG\",\n",
      "    \"13\": \"B-NAT\",\n",
      "    \"14\": \"I-NAT\",\n",
      "    \"15\": \"B-COL\",\n",
      "    \"16\": \"I-COL\",\n",
      "    \"17\": \"B-LEG\",\n",
      "    \"18\": \"I-LEG\",\n",
      "    \"19\": \"B-ACR\",\n",
      "    \"20\": \"I-ACR\",\n",
      "    \"21\": \"B-STR\",\n",
      "    \"22\": \"I-STR\",\n",
      "    \"23\": \"B-SCP\",\n",
      "    \"24\": \"I-SCP\",\n",
      "    \"25\": \"B-MOD\",\n",
      "    \"26\": \"I-MOD\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-ACR\": 19,\n",
      "    \"B-COL\": 15,\n",
      "    \"B-ID\": 1,\n",
      "    \"B-IND\": 5,\n",
      "    \"B-LEG\": 17,\n",
      "    \"B-LOC\": 9,\n",
      "    \"B-MOD\": 25,\n",
      "    \"B-NAT\": 13,\n",
      "    \"B-ORG\": 11,\n",
      "    \"B-PER\": 3,\n",
      "    \"B-SCP\": 23,\n",
      "    \"B-STP\": 7,\n",
      "    \"B-STR\": 21,\n",
      "    \"I-ACR\": 20,\n",
      "    \"I-COL\": 16,\n",
      "    \"I-ID\": 2,\n",
      "    \"I-IND\": 6,\n",
      "    \"I-LEG\": 18,\n",
      "    \"I-LOC\": 10,\n",
      "    \"I-MOD\": 26,\n",
      "    \"I-NAT\": 14,\n",
      "    \"I-ORG\": 12,\n",
      "    \"I-PER\": 4,\n",
      "    \"I-SCP\": 24,\n",
      "    \"I-STP\": 8,\n",
      "    \"I-STR\": 22,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ellabettison/.cache/huggingface/transformers/0013c32b74370df9aefe542a12f15ea645fd46de6e2da9581fe11599a444c53f.8aa372b3b9de4097ea2228f5cff8de30fda08756694d836fd1a08e6352fdaff8\n",
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing RobertaForSpanCategorization: ['bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'cls.predictions.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.9.output.dense.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.weight']\n",
      "- This IS expected if you are initializing RobertaForSpanCategorization from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSpanCategorization from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSpanCategorization were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'classifier.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'classifier.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/config.json from cache at /Users/ellabettison/.cache/huggingface/transformers/8fb343045f345372593fb03cc8edd339757b9b5fa164bfd4a071c33d81906423.81e683d6e4f3240a109c9cfd0742b01d443acc6fc2b120b20796fb85ddf0f393\n",
      "You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-ID\",\n",
      "    \"2\": \"I-ID\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-IND\",\n",
      "    \"6\": \"I-IND\",\n",
      "    \"7\": \"B-STP\",\n",
      "    \"8\": \"I-STP\",\n",
      "    \"9\": \"B-LOC\",\n",
      "    \"10\": \"I-LOC\",\n",
      "    \"11\": \"B-ORG\",\n",
      "    \"12\": \"I-ORG\",\n",
      "    \"13\": \"B-NAT\",\n",
      "    \"14\": \"I-NAT\",\n",
      "    \"15\": \"B-COL\",\n",
      "    \"16\": \"I-COL\",\n",
      "    \"17\": \"B-LEG\",\n",
      "    \"18\": \"I-LEG\",\n",
      "    \"19\": \"B-ACR\",\n",
      "    \"20\": \"I-ACR\",\n",
      "    \"21\": \"B-STR\",\n",
      "    \"22\": \"I-STR\",\n",
      "    \"23\": \"B-SCP\",\n",
      "    \"24\": \"I-SCP\",\n",
      "    \"25\": \"B-MOD\",\n",
      "    \"26\": \"I-MOD\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-ACR\": 19,\n",
      "    \"B-COL\": 15,\n",
      "    \"B-ID\": 1,\n",
      "    \"B-IND\": 5,\n",
      "    \"B-LEG\": 17,\n",
      "    \"B-LOC\": 9,\n",
      "    \"B-MOD\": 25,\n",
      "    \"B-NAT\": 13,\n",
      "    \"B-ORG\": 11,\n",
      "    \"B-PER\": 3,\n",
      "    \"B-SCP\": 23,\n",
      "    \"B-STP\": 7,\n",
      "    \"B-STR\": 21,\n",
      "    \"I-ACR\": 20,\n",
      "    \"I-COL\": 16,\n",
      "    \"I-ID\": 2,\n",
      "    \"I-IND\": 6,\n",
      "    \"I-LEG\": 18,\n",
      "    \"I-LOC\": 10,\n",
      "    \"I-MOD\": 26,\n",
      "    \"I-NAT\": 14,\n",
      "    \"I-ORG\": 12,\n",
      "    \"I-PER\": 4,\n",
      "    \"I-SCP\": 24,\n",
      "    \"I-STP\": 8,\n",
      "    \"I-STR\": 22,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/nlpaueb/legal-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ellabettison/.cache/huggingface/transformers/0013c32b74370df9aefe542a12f15ea645fd46de6e2da9581fe11599a444c53f.8aa372b3b9de4097ea2228f5cff8de30fda08756694d836fd1a08e6352fdaff8\n",
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing RobertaForSpanCategorization: ['bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'cls.predictions.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.9.output.dense.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.weight']\n",
      "- This IS expected if you are initializing RobertaForSpanCategorization from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSpanCategorization from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSpanCategorization were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'classifier.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'classifier.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `RobertaForSpanCategorization.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForSpanCategorization.forward`,  you can safely ignore this message.\n",
      "/Users/ellabettison/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 234\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1500\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "  0%|          | 1/1500 [03:33<14:08:39, 33.97s/it]\n",
      "\u001b[AThe following columns in the evaluation set don't have a corresponding argument in `RobertaForSpanCategorization.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForSpanCategorization.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 938\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1544, 'learning_rate': 0.0002483333333333333, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                   \n",
      "\n",
      "  0%|          | 1/1500 [04:09<14:08:39, 33.97s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ASaving model checkpoint to ./models/fine_tune_bert_output_span_cat/checkpoint-10\n",
      "Configuration saved in ./models/fine_tune_bert_output_span_cat/checkpoint-10/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06250406056642532, 'eval_f1_B-ID': 0, 'eval_f1_I-ID': 0, 'eval_f1_B-PER': 0, 'eval_f1_I-PER': 0, 'eval_f1_B-IND': 0, 'eval_f1_I-IND': 0, 'eval_f1_B-STP': 0, 'eval_f1_I-STP': 0, 'eval_f1_B-LOC': 0, 'eval_f1_I-LOC': 0, 'eval_f1_B-ORG': 0, 'eval_f1_I-ORG': 0, 'eval_f1_B-NAT': 0, 'eval_f1_I-NAT': 0, 'eval_f1_B-COL': 0, 'eval_f1_I-COL': 0, 'eval_f1_B-LEG': 0, 'eval_f1_I-LEG': 0, 'eval_f1_B-ACR': 0, 'eval_f1_I-ACR': 0, 'eval_f1_B-STR': 0, 'eval_f1_I-STR': 0, 'eval_f1_B-SCP': 0, 'eval_f1_I-SCP': 0, 'eval_f1_B-MOD': 0, 'eval_f1_I-MOD': 0, 'eval_macro_f1': 0.0, 'eval_runtime': 35.6809, 'eval_samples_per_second': 26.289, 'eval_steps_per_second': 1.654, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./models/fine_tune_bert_output_span_cat/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-10/special_tokens_map.json\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "  0%|          | 1/1500 [04:34<14:08:39, 33.97s/it]\n",
      "\u001b[AThe following columns in the evaluation set don't have a corresponding argument in `RobertaForSpanCategorization.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForSpanCategorization.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 938\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0618, 'learning_rate': 0.0002466666666666667, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                   \n",
      "\n",
      "  0%|          | 1/1500 [05:07<14:08:39, 33.97s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ASaving model checkpoint to ./models/fine_tune_bert_output_span_cat/checkpoint-20\n",
      "Configuration saved in ./models/fine_tune_bert_output_span_cat/checkpoint-20/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05514802783727646, 'eval_f1_B-ID': 0, 'eval_f1_I-ID': 0, 'eval_f1_B-PER': 0, 'eval_f1_I-PER': 0, 'eval_f1_B-IND': 0, 'eval_f1_I-IND': 0, 'eval_f1_B-STP': 0, 'eval_f1_I-STP': 0, 'eval_f1_B-LOC': 0, 'eval_f1_I-LOC': 0, 'eval_f1_B-ORG': 0, 'eval_f1_I-ORG': 0, 'eval_f1_B-NAT': 0, 'eval_f1_I-NAT': 0, 'eval_f1_B-COL': 0, 'eval_f1_I-COL': 0, 'eval_f1_B-LEG': 0, 'eval_f1_I-LEG': 0, 'eval_f1_B-ACR': 0, 'eval_f1_I-ACR': 0, 'eval_f1_B-STR': 0, 'eval_f1_I-STR': 0, 'eval_f1_B-SCP': 0, 'eval_f1_I-SCP': 0, 'eval_f1_B-MOD': 0, 'eval_f1_I-MOD': 0, 'eval_macro_f1': 0.0, 'eval_runtime': 32.6765, 'eval_samples_per_second': 28.706, 'eval_steps_per_second': 1.806, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./models/fine_tune_bert_output_span_cat/checkpoint-20/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-20/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-20/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fine_tune_bert_output_span_cat/checkpoint-50] due to args.save_total_limit\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "  0%|          | 1/1500 [05:31<14:08:39, 33.97s/it]\n",
      "\u001b[AThe following columns in the evaluation set don't have a corresponding argument in `RobertaForSpanCategorization.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForSpanCategorization.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 938\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0549, 'learning_rate': 0.000245, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                   \n",
      "\n",
      "  0%|          | 1/1500 [06:05<14:08:39, 33.97s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ASaving model checkpoint to ./models/fine_tune_bert_output_span_cat/checkpoint-30\n",
      "Configuration saved in ./models/fine_tune_bert_output_span_cat/checkpoint-30/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05388633534312248, 'eval_f1_B-ID': 0, 'eval_f1_I-ID': 0, 'eval_f1_B-PER': 0, 'eval_f1_I-PER': 0, 'eval_f1_B-IND': 0, 'eval_f1_I-IND': 0, 'eval_f1_B-STP': 0, 'eval_f1_I-STP': 0, 'eval_f1_B-LOC': 0, 'eval_f1_I-LOC': 0, 'eval_f1_B-ORG': 0, 'eval_f1_I-ORG': 0, 'eval_f1_B-NAT': 0, 'eval_f1_I-NAT': 0, 'eval_f1_B-COL': 0, 'eval_f1_I-COL': 0, 'eval_f1_B-LEG': 0, 'eval_f1_I-LEG': 0, 'eval_f1_B-ACR': 0, 'eval_f1_I-ACR': 0, 'eval_f1_B-STR': 0, 'eval_f1_I-STR': 0, 'eval_f1_B-SCP': 0, 'eval_f1_I-SCP': 0, 'eval_f1_B-MOD': 0, 'eval_f1_I-MOD': 0, 'eval_macro_f1': 0.0, 'eval_runtime': 34.0275, 'eval_samples_per_second': 27.566, 'eval_steps_per_second': 1.734, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./models/fine_tune_bert_output_span_cat/checkpoint-30/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-30/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-30/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fine_tune_bert_output_span_cat/checkpoint-20] due to args.save_total_limit\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "  0%|          | 1/1500 [06:40<14:08:39, 33.97s/it]\n",
      "\u001b[AThe following columns in the evaluation set don't have a corresponding argument in `RobertaForSpanCategorization.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForSpanCategorization.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 938\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0542, 'learning_rate': 0.00024333333333333336, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                   \n",
      "\n",
      "  0%|          | 1/1500 [07:15<14:08:39, 33.97s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ASaving model checkpoint to ./models/fine_tune_bert_output_span_cat/checkpoint-40\n",
      "Configuration saved in ./models/fine_tune_bert_output_span_cat/checkpoint-40/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.053893495351076126, 'eval_f1_B-ID': 0, 'eval_f1_I-ID': 0, 'eval_f1_B-PER': 0, 'eval_f1_I-PER': 0, 'eval_f1_B-IND': 0, 'eval_f1_I-IND': 0, 'eval_f1_B-STP': 0, 'eval_f1_I-STP': 0, 'eval_f1_B-LOC': 0, 'eval_f1_I-LOC': 0, 'eval_f1_B-ORG': 0, 'eval_f1_I-ORG': 0, 'eval_f1_B-NAT': 0, 'eval_f1_I-NAT': 0, 'eval_f1_B-COL': 0, 'eval_f1_I-COL': 0, 'eval_f1_B-LEG': 0, 'eval_f1_I-LEG': 0, 'eval_f1_B-ACR': 0, 'eval_f1_I-ACR': 0, 'eval_f1_B-STR': 0, 'eval_f1_I-STR': 0, 'eval_f1_B-SCP': 0, 'eval_f1_I-SCP': 0, 'eval_f1_B-MOD': 0, 'eval_f1_I-MOD': 0, 'eval_macro_f1': 0.0, 'eval_runtime': 34.8721, 'eval_samples_per_second': 26.898, 'eval_steps_per_second': 1.692, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./models/fine_tune_bert_output_span_cat/checkpoint-40/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-40/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fine_tune_bert_output_span_cat/checkpoint-30] due to args.save_total_limit\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "  0%|          | 1/1500 [07:41<14:08:39, 33.97s/it]\n",
      "\u001b[AThe following columns in the evaluation set don't have a corresponding argument in `RobertaForSpanCategorization.forward` and have been ignored: offset_mapping. If offset_mapping are not expected by `RobertaForSpanCategorization.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 938\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0549, 'learning_rate': 0.00024166666666666667, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A                                           \n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "\u001b[A\u001b[A                                            \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                   \n",
      "\n",
      "  0%|          | 1/1500 [08:17<14:08:39, 33.97s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ASaving model checkpoint to ./models/fine_tune_bert_output_span_cat/checkpoint-50\n",
      "Configuration saved in ./models/fine_tune_bert_output_span_cat/checkpoint-50/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.053401727229356766, 'eval_f1_B-ID': 0, 'eval_f1_I-ID': 0, 'eval_f1_B-PER': 0, 'eval_f1_I-PER': 0, 'eval_f1_B-IND': 0, 'eval_f1_I-IND': 0, 'eval_f1_B-STP': 0, 'eval_f1_I-STP': 0, 'eval_f1_B-LOC': 0, 'eval_f1_I-LOC': 0, 'eval_f1_B-ORG': 0, 'eval_f1_I-ORG': 0, 'eval_f1_B-NAT': 0, 'eval_f1_I-NAT': 0, 'eval_f1_B-COL': 0, 'eval_f1_I-COL': 0, 'eval_f1_B-LEG': 0, 'eval_f1_I-LEG': 0, 'eval_f1_B-ACR': 0, 'eval_f1_I-ACR': 0, 'eval_f1_B-STR': 0, 'eval_f1_I-STR': 0, 'eval_f1_B-SCP': 0, 'eval_f1_I-SCP': 0, 'eval_f1_B-MOD': 0, 'eval_f1_I-MOD': 0, 'eval_macro_f1': 0.0, 'eval_runtime': 35.9208, 'eval_samples_per_second': 26.113, 'eval_steps_per_second': 1.643, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./models/fine_tune_bert_output_span_cat/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fine_tune_bert_output_span_cat/checkpoint-50/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fine_tune_bert_output_span_cat/checkpoint-40] due to args.save_total_limit\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [56], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RobertaForSpanCategorization\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlpaueb/legal-bert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, id2label\u001b[38;5;241m=\u001b[39mid2label, label2id\u001b[38;5;241m=\u001b[39mlabel2id)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      6\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,\n\u001b[1;32m      7\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1410\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1411\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1412\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1413\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1414\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/trainer.py:1651\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1649\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1650\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1651\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1653\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1654\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1655\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1656\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1657\u001b[0m ):\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2344\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2345\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2348\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/trainer.py:2377\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2376\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2377\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2378\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2379\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [50], line 56\u001b[0m, in \u001b[0;36mRobertaForSpanCategorization.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m---> 56\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     68\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:848\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    841\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    842\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    843\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    846\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    847\u001b[0m )\n\u001b[0;32m--> 848\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    849\u001b[0m     embedding_output,\n\u001b[1;32m    850\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    851\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    852\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    853\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    854\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    855\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    856\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    857\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    858\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    859\u001b[0m )\n\u001b[1;32m    860\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    861\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    515\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    516\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    517\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    525\u001b[0m         hidden_states,\n\u001b[1;32m    526\u001b[0m         attention_mask,\n\u001b[1;32m    527\u001b[0m         layer_head_mask,\n\u001b[1;32m    528\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    529\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    530\u001b[0m         past_key_value,\n\u001b[1;32m    531\u001b[0m         output_attentions,\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:409\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    398\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    399\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    407\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    410\u001b[0m         hidden_states,\n\u001b[1;32m    411\u001b[0m         attention_mask,\n\u001b[1;32m    412\u001b[0m         head_mask,\n\u001b[1;32m    413\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    414\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    415\u001b[0m     )\n\u001b[1;32m    416\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    418\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:336\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    328\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    335\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 336\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    337\u001b[0m         hidden_states,\n\u001b[1;32m    338\u001b[0m         attention_mask,\n\u001b[1;32m    339\u001b[0m         head_mask,\n\u001b[1;32m    340\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    341\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    342\u001b[0m         past_key_value,\n\u001b[1;32m    343\u001b[0m         output_attentions,\n\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    345\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    346\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:222\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    220\u001b[0m     value_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m1\u001b[39m], value_layer], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    221\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey(hidden_states))\n\u001b[1;32m    223\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue(hidden_states))\n\u001b[1;32m    225\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def model_init():\n",
    "    # For reproducibility\n",
    "    return RobertaForSpanCategorization.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", id2label=id2label, label2id=label2id)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_val_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "888e6cd309e747ffecffaf2f7c62b6289e92b2288d45615be4f1da43735c96a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
